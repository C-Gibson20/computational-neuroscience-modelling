{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@markstent/dynamic-time-warping-a8c5027defb6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dtaidistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dtaidistance import dtw, dtw_visualisation as dtwvis\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_h5_structure(g, indent=0):\n",
    "    \"\"\"\n",
    "    Recursively prints the structure of an HDF5 group.\n",
    "    \n",
    "    Parameters:\n",
    "      - g: an h5py Group or File object.\n",
    "      - indent: current indentation level (for pretty-printing).\n",
    "    \"\"\"\n",
    "    for key in g.keys():\n",
    "        item = g[key]\n",
    "        print(\"  \" * indent + f\"{key}: {type(item).__name__}\")\n",
    "        if isinstance(item, h5py.Group):\n",
    "            print_h5_structure(item, indent+1)\n",
    "\n",
    "with h5py.File('trajectory_data.h5', 'r') as f:\n",
    "    print(\"HDF5 File Structure:\")\n",
    "    print_h5_structure(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_trajectory(traj, new_length):\n",
    "    \"\"\"\n",
    "    Resample a 1D trajectory to a specified new_length using linear interpolation.\n",
    "    \"\"\"\n",
    "    current_length = len(traj)\n",
    "    t_old = np.linspace(0, 1, current_length)\n",
    "    t_new = np.linspace(0, 1, new_length)\n",
    "    return np.interp(t_new, t_old, traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_key(key):\n",
    "    return int(key.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_trajectory(x, y):\n",
    "    \"\"\"Normalize x and y trajectories to have zero mean and unit variance.\"\"\"\n",
    "    x = (x - np.mean(x)) / np.std(x)\n",
    "    y = (y - np.mean(y)) / np.std(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sorted_trajectories_subplots(actual_mean_trajectories, model_mean_trajectories):\n",
    "    \"\"\"\n",
    "    For each start position (e.g., LEFT, RIGHT, CENTER), create a figure with 9 subplots\n",
    "    (arranged in a 3x3 grid) comparing the corresponding actual and model trajectories.\n",
    "    \n",
    "    The trajectories are paired by the sorted order of their keys (even if the keys differ).\n",
    "    Each subplot displays the normalized actual (labeled with its key) and model trajectories\n",
    "    (labeled with its key), along with the computed DTW distance.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary mapping (start_position, actual_key, model_key) to the DTW distance.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for sp in sorted(actual_mean_trajectories.keys()):\n",
    "        fig, axs = plt.subplots(6, 3, figsize=(15, 15))\n",
    "        axs = axs.flatten() \n",
    "        \n",
    "        actual_keys = sorted(actual_mean_trajectories[sp].keys())\n",
    "        model_keys  = sorted(model_mean_trajectories[sp].keys())\n",
    "        \n",
    "        for i, (key_actual, key_model) in enumerate(zip(actual_keys, model_keys)):\n",
    "            if i >= 18:\n",
    "                break\n",
    "            \n",
    "            traj_actual = actual_mean_trajectories[sp][key_actual]\n",
    "            traj_model  = model_mean_trajectories[sp][key_model]\n",
    "            ax = axs[i]\n",
    "            \n",
    "            if traj_actual and traj_model:\n",
    "                x1, y1 = traj_actual\n",
    "                x2, y2 = traj_model\n",
    "\n",
    "                x1_norm, y1_norm = normalize_trajectory(np.array(x1), np.array(y1))\n",
    "                x2_norm, y2_norm = normalize_trajectory(np.array(x2), np.array(y2))\n",
    "                \n",
    "                traj1 = np.vstack((x1_norm, y1_norm)).T\n",
    "                traj2 = np.vstack((x2_norm, y2_norm)).T\n",
    "                \n",
    "                distance = dtw.distance(traj1.flatten(), traj2.flatten())\n",
    "                results[(sp, key_actual, key_model)] = distance\n",
    "                \n",
    "                ax.plot(x1_norm, y1_norm, label=f'Actual {key_actual}')\n",
    "                ax.plot(x2_norm, y2_norm, label=f'Model {key_model}')\n",
    "                ax.set_title(f'Speed {key_actual}/{key_model}\\nDTW: {distance:.2f}')\n",
    "                ax.legend(fontsize=8)\n",
    "                ax.tick_params(axis='both', labelsize=8)\n",
    "            else:\n",
    "                ax.set_title(\"Missing trajectory\", fontsize=10)\n",
    "        \n",
    "        for j in range(i + 1, len(axs)):\n",
    "            axs[j].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'{sp} Speed Comparisons', fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_trajectories(filename, deep=False):\n",
    "    start_positions = ['LEFT', 'RIGHT', 'CENTER']\n",
    "    data_speeds = [-8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    trajectories = {sp: {s: [] for s in data_speeds} for sp in start_positions}\n",
    "    mean_trajectories = {sp: {s: [] for s in data_speeds} for sp in start_positions}\n",
    "\n",
    "    cmap = plt.get_cmap(\"viridis\")  \n",
    "    norm = mcolors.Normalize(vmin=min(data_speeds), vmax=max(data_speeds))\n",
    "\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        for sp in start_positions:\n",
    "            x_group = f[sp]['x']\n",
    "            y_group = f[sp]['y']\n",
    "            keys = sorted(x_group.keys(), key=lambda k: int(k))\n",
    "            \n",
    "            for key in keys:\n",
    "                speed = int(key)                   \n",
    "                x_arr = x_group[key][:]\n",
    "                y_arr = y_group[key][:]\n",
    "                trajectories[sp][speed].append((x_arr, y_arr))\n",
    "                \n",
    "    for sp in start_positions:\n",
    "        for s in data_speeds:\n",
    "            traj_list = trajectories[sp][s]\n",
    "            max_length = max(len(x) for x, _ in traj_list)\n",
    "            avg_x = np.mean(np.array([resample_trajectory(x, max_length) for x, _ in traj_list]), axis=0)\n",
    "            avg_y = np.mean(np.array([resample_trajectory(y, max_length) for _, y in traj_list]), axis=0)\n",
    "                \n",
    "            grouped_x = defaultdict(list)\n",
    "            for x_val, y_val in zip(avg_x, avg_y):\n",
    "\n",
    "                rounded_y = round(y_val/2)*2 if deep else round(y_val)\n",
    "                grouped_x[rounded_y].append(x_val)\n",
    "                \n",
    "            rounded_ys = sorted(grouped_x.keys())\n",
    "            averaged_xs = [np.mean(grouped_x[ry]) for ry in rounded_ys]\n",
    "            mean_trajectories[sp][s] = (np.array(averaged_xs), np.array(rounded_ys))\n",
    "\n",
    "    fig, axs = plt.subplots(2, len(start_positions), figsize=(18, 10), sharex=True, sharey=True)\n",
    "    for ax, sp in zip(axs[0], start_positions):\n",
    "        for s in data_speeds[8:]:\n",
    "            if mean_trajectories[sp][s]:\n",
    "                avg_x, avg_y = mean_trajectories[sp][s]\n",
    "                ax.plot(avg_x, avg_y, color=cmap(norm(s)), label=f'Speed {s}')\n",
    "        ax.set_title(f'Start Position: {sp}')\n",
    "        ax.set_xlabel('X Coordinate')\n",
    "        ax.set_ylabel('Y Coordinate')\n",
    "        ax.legend()\n",
    "    for ax, sp in zip(axs[1], start_positions):\n",
    "        for s in data_speeds[:8]:\n",
    "            if mean_trajectories[sp][s]:\n",
    "                avg_x, avg_y = mean_trajectories[sp][s]\n",
    "                ax.plot(avg_x, avg_y, color=cmap(norm(s)), label=f'Speed {s}')\n",
    "        ax.set_title(f'Start Position: {sp}')\n",
    "        ax.set_xlabel('X Coordinate')\n",
    "        ax.set_ylabel('Y Coordinate')\n",
    "        ax.legend()\n",
    "\n",
    "    fig.suptitle('Rulebased Mean Trajectories for Different Start Positions and Speeds')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return mean_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_trajectory(filename_acc_data, group_names):\n",
    "    start_positions = ['LEFT', 'RIGHT', 'CENTER']\n",
    "    actual_speeds = [-20, -17.5, -15, -12.5, -10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10, 12.5, 15, 17.5, 20]\n",
    "    trajectories = {sp: {s: [] for s in actual_speeds} for sp in start_positions}  \n",
    "    actual_mean_trajectories = {sp: {s: [] for s in actual_speeds} for sp in start_positions}  \n",
    "\n",
    "    cmap = plt.get_cmap(\"viridis\")  \n",
    "    norm = mcolors.Normalize(vmin=min(actual_speeds), vmax=max(actual_speeds))\n",
    "\n",
    "    with h5py.File(filename_acc_data, 'r') as f:\n",
    "        for group in group_names:\n",
    "            print(f\"Processing group: {group}\")\n",
    "            x_group = f[f'{group}/neck_x_mirror_smooth']\n",
    "            y_group = f[f'{group}/neck_y_mirror_smooth']\n",
    "            speed_dataset = f[f'{group}/trial_settings/speed_direction'][:]\n",
    "            direction_dataset = f[f'{group}/trial_settings/initial_position_X_SIDE'][:]\n",
    "\n",
    "            keys = sorted(x_group.keys(), key=sort_key)\n",
    "\n",
    "            data_speeds = np.array([float(s.decode('utf-8')) if isinstance(s, bytes) else float(s) for s in speed_dataset])\n",
    "            directions = [d.decode('utf-8') if isinstance(d, bytes) else d for d in direction_dataset]\n",
    "\n",
    "            for i, key in enumerate(keys):\n",
    "                x_arr = x_group[key][:]\n",
    "                y_arr = y_group[key][:]\n",
    "                trial_speed = data_speeds[i]\n",
    "                rounded_speed = round(trial_speed / 2.5) * 2.5    \n",
    "                dir_val = directions[i]\n",
    "                trajectories[dir_val][rounded_speed].append((x_arr, y_arr))\n",
    "\n",
    "    for sp, speed_dict in trajectories.items():\n",
    "        for speed, traj_list in speed_dict.items():\n",
    "            max_length = max(len(x) for x, _ in traj_list)\n",
    "            avg_x = np.mean(np.array([resample_trajectory(x, max_length) for x, _ in traj_list]), axis=0)\n",
    "            avg_y = np.mean(np.array([resample_trajectory(y, max_length) for _, y in traj_list]), axis=0)\n",
    "\n",
    "            grouped_x = defaultdict(list)\n",
    "            for x_val, y_val in zip(avg_x, avg_y):\n",
    "                rounded_y = round(y_val)\n",
    "                grouped_x[rounded_y].append(x_val)\n",
    "\n",
    "            rounded_ys = sorted(grouped_x.keys())\n",
    "            averaged_xs = [np.mean(grouped_x[ry]) for ry in rounded_ys]\n",
    "            actual_mean_trajectories[sp][speed] = (np.array(averaged_xs), np.array(rounded_ys))\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(18, 10), sharex=True, sharey=True)\n",
    "\n",
    "    for ax, sp in zip(axs[0], start_positions):  \n",
    "        for speed in actual_speeds[8:]:\n",
    "            avg_x, avg_y = actual_mean_trajectories[sp][speed]\n",
    "            ax.plot(avg_x, avg_y, color=cmap(norm(speed)), label=f'Speed {speed}')\n",
    "        ax.set_title(f'Start Position: {sp}')\n",
    "        ax.set_xlabel('X Coordinate')\n",
    "        ax.set_ylabel('Y Coordinate')\n",
    "        ax.legend()\n",
    "    for ax, sp in zip(axs[1], start_positions):  \n",
    "        for speed in actual_speeds[:8]:\n",
    "            avg_x, avg_y = actual_mean_trajectories[sp][speed]\n",
    "            ax.plot(avg_x, avg_y, color=cmap(norm(speed)), label=f'Speed {speed}')\n",
    "        ax.set_title(f'Start Position: {sp}')\n",
    "        ax.set_xlabel('X Coordinate')\n",
    "        ax.set_ylabel('Y Coordinate')\n",
    "        ax.legend()\n",
    "\n",
    "    fig.suptitle('Average Trajectories for Different Start Positions (Combined Groups)') \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return actual_mean_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auc(x, y):\n",
    "    valid = ~np.isnan(y)\n",
    "    if not valid.any():\n",
    "        return np.nan\n",
    "    auc = 0.0\n",
    "    splits = np.where(~valid)[0]\n",
    "    segments = []\n",
    "    start = 0\n",
    "    for idx in splits:\n",
    "        if idx > start:\n",
    "            segments.append((start, idx))\n",
    "        start = idx + 1\n",
    "    if start < len(y):\n",
    "        segments.append((start, len(y)))\n",
    "    for s, e in segments:\n",
    "        auc += np.trapz(y[s:e], x[s:e])\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dtw_scores(actual_mean_trajectories, list_of_model_trajectories, model_names=None):\n",
    "    \"\"\"\n",
    "    For each start position (LEFT, CENTER, RIGHT), pairs the actual trajectories with the\n",
    "    model trajectories (sorted by speed key, even if the keys differ) and computes the DTW\n",
    "    distance for each pair. All points are placed on a continuous x-axis (ordered by group)\n",
    "    so that an area under the curve (AUC) can be computed for each model.\n",
    "    \n",
    "    In addition to an overall DTW score comparison plot, this function produces a second figure \n",
    "    containing a subplot for each individual model's DTW score curve. Both plots include:\n",
    "        - Vertical dashed lines at the group midpoints (labeled with the start position)\n",
    "        - Faint vertical dashed lines at the boundaries between start positions.\n",
    "    \n",
    "    Args:\n",
    "        actual_mean_trajectories (dict): {start_pos: {speed_key: (x, y), ...}, ...}\n",
    "        list_of_model_trajectories (list): List of dictionaries structured like actual_mean_trajectories.\n",
    "        model_names (list, optional): Names for each model. Defaults to [\"Model 1\", \"Model 2\", ...].\n",
    "    \n",
    "    Returns:\n",
    "        dict: auc_dict mapping model_name -> AUC value (using np.trapz over valid segments).\n",
    "    \"\"\"\n",
    "    \n",
    "    start_positions = ['LEFT', 'CENTER', 'RIGHT']\n",
    "    \n",
    "    group_counts = [len(sorted(actual_mean_trajectories[sp].keys(), key=lambda s: float(s))) if sp in actual_mean_trajectories else 0 for sp in start_positions]\n",
    "    total_points = sum(group_counts)\n",
    "    global_x = np.arange(total_points)\n",
    "    \n",
    "    midpoints = {}\n",
    "    start_idx = 0\n",
    "    for sp, count in zip(start_positions, group_counts):\n",
    "        if count > 0:\n",
    "            midpoints[sp] = (start_idx + start_idx + count - 1) / 2.0\n",
    "        start_idx += count\n",
    "\n",
    "    # Compute boundaries between groups.\n",
    "    cumulative_counts = np.cumsum(group_counts)\n",
    "    group_boundaries = []\n",
    "    for boundary in cumulative_counts[:-1]:\n",
    "        group_boundaries.append(boundary - 0.5)\n",
    "    \n",
    "    model_curves = {name: [] for name in model_names}\n",
    "    results = {}\n",
    "    \n",
    "    for sp in start_positions:\n",
    "        actual_keys = sorted(actual_mean_trajectories.get(sp, {}).keys(), key=lambda s: float(s))\n",
    "        n_points = len(actual_keys)\n",
    "        \n",
    "        for m_idx, model in enumerate(list_of_model_trajectories):\n",
    "            model_name = model_names[m_idx]\n",
    "            if sp not in model:\n",
    "                model_curves[model_name].extend([np.nan] * n_points)\n",
    "                continue\n",
    "\n",
    "            model_keys = sorted(model[sp].keys(), key=lambda s: float(s))\n",
    "            pairs = list(zip(actual_keys, model_keys))\n",
    "            for a_key, m_key in pairs:\n",
    "                traj_actual = actual_mean_trajectories[sp][a_key]\n",
    "                traj_model  = model[sp][m_key]\n",
    "                \n",
    "                if traj_actual and traj_model:\n",
    "                    x1, y1 = np.array(traj_actual[0]), np.array(traj_actual[1])\n",
    "                    x2, y2 = np.array(traj_model[0]), np.array(traj_model[1])\n",
    "                    x1_norm, y1_norm = normalize_trajectory(x1, y1)\n",
    "                    x2_norm, y2_norm = normalize_trajectory(x2, y2)\n",
    "                    \n",
    "                    traj1 = np.vstack((x1_norm, y1_norm)).T\n",
    "                    traj2 = np.vstack((x2_norm, y2_norm)).T\n",
    "                    \n",
    "                    distance = dtw.distance(traj1.flatten(), traj2.flatten())\n",
    "                    results[(model_name, sp, a_key, m_key)] = distance\n",
    "                    model_curves[model_name].append(distance)\n",
    "                else:\n",
    "                    model_curves[model_name].append(np.nan)\n",
    "\n",
    "    # ---------------- Overall Plot ----------------\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    cmap = plt.get_cmap('tab10', len(list_of_model_trajectories))\n",
    "    \n",
    "    for i, model_name in enumerate(model_names):\n",
    "        scores = np.array(model_curves[model_name])\n",
    "        plt.plot(global_x, scores, marker='o', linestyle='-', color=cmap(i), label=model_name)\n",
    "    \n",
    "    for sp, pos in midpoints.items():\n",
    "        plt.axvline(pos, color='grey', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    for boundary in group_boundaries:\n",
    "        plt.axvline(boundary, color='grey', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.xticks(list(midpoints.values()), list(midpoints.keys()))\n",
    "    plt.xlabel(\"Start Position\")\n",
    "    plt.ylabel(\"DTW Score\")\n",
    "    plt.title(\"DTW Score Comparisons\")\n",
    "    plt.legend(title=\"Model\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ---------------- Compute AUC ----------------\n",
    "    auc_dict = {model_name: compute_auc(global_x, np.array(scores))\n",
    "                for model_name, scores in model_curves.items()}\n",
    "    \n",
    "    # ---------------- Individual Subplots ----------------\n",
    "    n_models = len(model_names)\n",
    "    fig, axs = plt.subplots(n_models, 1, figsize=(10, 3 * n_models), sharex=True)\n",
    "    \n",
    "    for i, model_name in enumerate(model_names):\n",
    "        ax = axs[i]\n",
    "        scores = np.array(model_curves[model_name])\n",
    "        ax.plot(global_x, scores, marker='o', linestyle='-', color=cmap(i))\n",
    "        ax.set_title(f\"{model_name} DTW Score Curve (AUC = {auc_dict[model_name]:.3f})\")\n",
    "        ax.set_ylabel(\"DTW Score\")\n",
    "    \n",
    "        for sp, pos in midpoints.items():\n",
    "            ax.axvline(pos, color='grey', linestyle='--', alpha=0.5)\n",
    "            ax.text(pos, ax.get_ylim()[1]*0.95, sp, ha='center', va='top', fontsize=8, color='grey')\n",
    "    \n",
    "        for boundary in group_boundaries:\n",
    "            ax.axvline(boundary, color='grey', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    axs[-1].set_xlabel(\"Global x (Continuous Index)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return auc_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = [\n",
    "    'BRAC68537c/221109.0',\n",
    "    'BRAC68537c/221111.0',\n",
    "    'BRAC68537c/221114.0',\n",
    "    'BRAC68537c/221115.0',\n",
    "    'BRAC68537c/221117.0',\n",
    "    'BRAC68537d/221109.0',\n",
    "    'BRAC68537d/221111.0',\n",
    "    'BRAC68537d/221114.0',\n",
    "    'BRAC68537d/221115.0',\n",
    "    'BRAC68537d/221117.0'\n",
    "]\n",
    "\n",
    "actual_mean_trajectories = plot_actual_trajectory('trajectory_data.h5', group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep RL Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_deep_rl_data = '../../scripts/deep_rl_mean_coords.h5'\n",
    "deep_mean_trajectories = plot_model_trajectories(filename_deep_rl_data, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep RL Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = compare_sorted_trajectories_subplots(actual_mean_trajectories, deep_mean_trajectories)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rulebased Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_linear_data = '../../scripts/linear_mean_coords.h5'\n",
    "linear_mean_trajectories = plot_model_trajectories(filename_linear_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_random_data = '../../scripts/random_mean_coords.h5'\n",
    "random_mean_trajectories = plot_model_trajectories(filename_random_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rulebased Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = compare_sorted_trajectories_subplots(actual_mean_trajectories, linear_mean_trajectories)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = compare_sorted_trajectories_subplots(actual_mean_trajectories, random_mean_trajectories)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Aproximation Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_rl_data = '../../scripts/rl_mean_coords.h5'\n",
    "rl_mean_trajectories = plot_model_trajectories(filename_rl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Approximation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compare_sorted_trajectories_subplots(actual_mean_trajectories, rl_mean_trajectories)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Plot Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Deep RL', 'Linear', 'Random', 'RL']\n",
    "model_trajectories = [deep_mean_trajectories, linear_mean_trajectories, random_mean_trajectories, rl_mean_trajectories]\n",
    "plot_dtw_scores(actual_mean_trajectories, model_trajectories, model_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal_mazes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
