{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import neat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import multimodal_mazes\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "width=21\n",
    "height=21\n",
    "n_prey = 1\n",
    "n_steps = 100\n",
    "n_trials = 100\n",
    "pk = 40 # the width of the prey's Gaussian signal (in rc)\n",
    "visible_steps = n_steps\n",
    "scenario =  \"Constant\"\n",
    "motion = \"Linear\"\n",
    "multisensory = \"Unisensory\"\n",
    "\n",
    "if scenario == \"Static\":\n",
    "    pc = 0.0\n",
    "    pm = 0\n",
    "    pe = 1\n",
    "    motion = None\n",
    "elif scenario == \"Constant\":\n",
    "    pc = 0.0\n",
    "    pm = 1\n",
    "    pe = 0.998\n",
    "    noise = 0.002\n",
    "    case = \"2\"\n",
    "elif scenario == \"Random\":\n",
    "    pc = 0.0\n",
    "    pm = 1\n",
    "    pe = 0.2\n",
    "    motion = \"Levy\"\n",
    "    case = \"1\"\n",
    "elif scenario == \"Two Prey\":\n",
    "    pc = 0.0\n",
    "    pm = 0\n",
    "    pe = 0.998\n",
    "    noise = 0.002\n",
    "    multisensory = \"Balanced\"\n",
    "    case = \"4\"\n",
    "    n_prey = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_steps = n_steps\n",
    "pm = 0\n",
    "\n",
    "agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy='-/-')\n",
    "# time, path, prey_state, preys, env_log = multimodal_mazes.linear_prey_trial(width=width, height=height, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk,n_steps=n_steps, scenario=scenario, case=case, motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=pm, pe=pe, log_env=True)\n",
    "trial = multimodal_mazes.PredatorTrial(width=width, height=height, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk,n_steps=n_steps, scenario=scenario, case=case, motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=pm, pe=pe, log_env=True)\n",
    "time, path, prey_state, preys, env_log = trial.run_trial()\n",
    "print(prey_state)\n",
    "print(len(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "prey_markers = ['P', 'X']\n",
    "\n",
    "# Colormaps \n",
    "from matplotlib import colors\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "cmap_wall = cm.binary\n",
    "cmap_wall.set_under('k', alpha=0)\n",
    "\n",
    "cmap_ch0 = colors.LinearSegmentedColormap.from_list(\n",
    "    \"\", [\"white\", \"xkcd:ultramarine\"]\n",
    ")\n",
    "\n",
    "cmap_ch1 = colors.LinearSegmentedColormap.from_list(\n",
    "    \"\", [\"white\", \"xkcd:magenta\"]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Environment \n",
    "plt.imshow(1 - env_log[0][:, :, -1], clim=[0.1,1.0], cmap=cmap_wall, alpha=0.25, zorder=1)\n",
    "plt.imshow((cmap_ch0(env_log[1][:,:,0]) + cmap_ch1(env_log[1][:,:,1]))/2, interpolation='gaussian', zorder=0) \n",
    "\n",
    "# Adjust axes \n",
    "plt.xlim([(pk//2) - 1, width + pk//2])\n",
    "plt.ylim([height + pk//2, (pk//2) - 1]) \n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Initial data \n",
    "agnt_animation = ax.scatter([], [], s=120, color='k', zorder=3)\n",
    "preys_animation = [[] for _ in preys]\n",
    "for a, prey in enumerate(preys): \n",
    "    if scenario == \"Static\":\n",
    "     preys_animation[a] = ax.scatter([], [], s=60, color='k', alpha=0.5, marker=prey_markers[prey.cues], zorder=2)\n",
    "    elif scenario != \"Static\": \n",
    "        preys_animation[a] = ax.scatter([], [], s=60, color='k', alpha=0.5, marker=prey_markers[0], zorder=2)\n",
    "\n",
    "# Animate \n",
    "def update_animation(t):\n",
    "    plt.imshow((cmap_ch0(env_log[t][:,:,0]) + cmap_ch1(env_log[t][:,:,1]))/2, interpolation='gaussian', zorder=0) \n",
    "\n",
    "    agnt_animation.set_offsets([path[t, 1], path[t, 0]])\n",
    "\n",
    "    for a, prey in enumerate(preys): \n",
    "        try:\n",
    "            preys_animation[a].set_offsets([prey.path[t][1], prey.path[t][0]])\n",
    "        except:\n",
    "            preys_animation[a].set(alpha=0)\n",
    "\n",
    "#anim = animation.FuncAnimation(fig, update_animation, frames=range(0, len(path)), blit=False)\n",
    "anim = animation.FuncAnimation(fig, update_animation, frames=range(0, 20), blit=False)\n",
    "anim.save(\"Test.gif\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 channel colormap\n",
    "input_values = np.linspace(0,1,num=11)\n",
    "a,b = np.meshgrid(input_values, input_values)\n",
    "\n",
    "plt.imshow((cmap_ch0(a) + cmap_ch1(b))/2, zorder=0, origin='lower')\n",
    "plt.xticks(ticks=range(len(input_values)), labels=np.round(input_values,1), rotation='vertical')\n",
    "plt.yticks(ticks=range(len(input_values)), labels=np.round(input_values,1))\n",
    "plt.xlabel('Ch0 input')\n",
    "plt.ylabel('Ch1 input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage capture vs speed per case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Capture vs speed\n",
    "\n",
    "noise = 0.002\n",
    "pe = 0.998\n",
    "n_trials = 10\n",
    "cases = [\"1\", \"2\", \"3\"]\n",
    "speeds = np.linspace(start=0.0, stop=1.0, num=10)\n",
    "policies = multimodal_mazes.AgentRuleBased.policies + multimodal_mazes.AgentRuleBasedMemory.policies + [\"Levy\"]\n",
    "colors = multimodal_mazes.AgentRuleBased.colors + multimodal_mazes.AgentRuleBasedMemory.colors + [list(np.array([24, 156, 196, 255]) / 255)]\n",
    "results = np.zeros((len(speeds), len(policies)))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharex=True, sharey=True)\n",
    "fig.tight_layout(rect=[0,0.1, 1, 0.9])\n",
    "fig.suptitle(f\"{motion}, {multisensory} - Percentage Captured vs Speed\")\n",
    "\n",
    "\n",
    "# Test agents\n",
    "for case in tqdm(range(len(cases))):\n",
    "    for a, speed in tqdm(enumerate(speeds)):\n",
    "        for b, policy in enumerate(policies): \n",
    "            if policy in multimodal_mazes.AgentRuleBased.policies:\n",
    "                agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy=policy)\n",
    "            elif policy in multimodal_mazes.AgentRuleBasedMemory.policies:\n",
    "                agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "                agnt.alpha = 0.6\n",
    "                \n",
    "            elif policy == \"Levy\":\n",
    "                agnt = multimodal_mazes.AgentRandom(location=None, channels=[0,0], motion=policy)\n",
    "\n",
    "            evaluator = multimodal_mazes.LinearPreyFitnessEvaluator(height=height, width=width, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=cases[case], motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=speeds[a], pe=pe)\n",
    "            _, _, _, _, captured, _ = evaluator.evaluate(n_trials=n_trials)\n",
    "            results[a, b] = captured\n",
    "    \n",
    "\n",
    "    for b, policy in enumerate(policies): \n",
    "        axs[case].plot(speeds, results[:,b], color=colors[b])    \n",
    "        axs[case].set_title(f\"Case {case+1}\")\n",
    "\n",
    "axs[0].set(xlabel='Speed', ylabel='Percentage Captured')\n",
    "axs[0].set_xticks(np.arange(0.0, 1.1, 0.2));\n",
    "fig.legend(loc='center right', bbox_to_anchor=(1.05, 0.5), labels=policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Capture vs speed\n",
    "cases = [\"1\", \"2\", \"3\"]\n",
    "speeds = np.linspace(start=0.0, stop=1.0, num=10)\n",
    "repeats = [i for i in range(4)]\n",
    "n_trials = 100\n",
    "pe = 1\n",
    "noise = 0\n",
    "policy = multimodal_mazes.AgentRuleBased.policies[0]\n",
    "agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy=policy)\n",
    "# policy = multimodal_mazes.AgentRuleBasedMemory.policies[0]\n",
    "# agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "colors = [(\"#346ea8\"), (\"#ff760d\"), (\"#fa020f\")]\n",
    "results = np.zeros((len(speeds), len(repeats)))\n",
    "trials = {n: {case: {pm: [] for pm in range(len(speeds))} for case in range(len(cases))} for n in range(len(repeats))}\n",
    "trials_prey = {n: {case: {pm: [] for pm in range(len(speeds))} for case in range(len(cases))} for n in range(len(repeats))}\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True, sharey=True)\n",
    "fig.tight_layout(rect=[0,0.1, 1, 0.9])\n",
    "fig.suptitle(f\"{multisensory} {policy} Percentage Captured vs Speed\")\n",
    "\n",
    "for case in tqdm(range(len(cases))):\n",
    "    capture_results = np.zeros((2, len(speeds)))\n",
    "    for a, speed in tqdm(enumerate(speeds)):\n",
    "        \n",
    "        for b in repeats:\n",
    "            captured = 0\n",
    "            evaluator = multimodal_mazes.LinearPreyFitnessEvaluator(height=height, width=width, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=cases[case], motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=speeds[a], pe=pe)\n",
    "            _, _, paths, preys, captured, _ = evaluator.evaluate(n_trials=n_trials)\n",
    "            results[a, b] = captured\n",
    "            trials[b][case][a] = paths\n",
    "            trials_prey[b][case][a] = preys\n",
    "        capture_results[0, a] = np.mean(results[a,:])\n",
    "        capture_results[1, a] = np.std(results[a,:])\n",
    "    \n",
    "    for b in repeats:\n",
    "        axs[case].plot(speeds, results[:,b], color = colors[case], alpha = 0.2)\n",
    "        axs[case].set_title(f\"Case {case+1}\")\n",
    "        axs[case].plot(speeds, capture_results[0, :], color=colors[case])\n",
    "        axs[3].plot(speeds, capture_results[0, :], color=colors[case])\n",
    "        axs[case].errorbar(speeds, capture_results[0, :], yerr=capture_results[1, :], color=colors[case])\n",
    "        axs[3].errorbar(speeds, capture_results[0, :], yerr=capture_results[1, :], color=colors[case])\n",
    "\n",
    "axs[0].set(xlabel='Speed', ylabel='Percentage Captured')\n",
    "axs[0].set_xticks(np.arange(0.0, 1.1, 0.2));\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_ylim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_speeds = [-8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "direction_coords = {sp: {'y': {pm: [] for pm in data_speeds}, 'x': {pm: [] for pm in data_speeds}} for sp in ['LEFT', 'RIGHT', 'CENTER']}\n",
    "direction_mean_coords = {sp: {'mean_x': {pm: [] for pm in data_speeds}, 'unique_y': {pm: [] for pm in data_speeds}} for sp in ['LEFT', 'RIGHT', 'CENTER']}\n",
    "\n",
    "for n in range(len(repeats)):\n",
    "    for a in range(9):\n",
    "        for case in range(len(cases)):\n",
    "            for trial in range(len(trials[n][case][a])):\n",
    "                initial_pos = trials_prey[n][case][a][trial][0].location[1]\n",
    "                final_pos = trials_prey[n][case][a][trial][-1].location[1]\n",
    "                if case == 0:\n",
    "                    trial_start_pos = 'CENTER'\n",
    "                    trial_speed = a if final_pos > 30 else -a\n",
    "                elif case == 1:\n",
    "                    trial_start_pos = 'LEFT' if initial_pos < 30 else 'RIGHT'\n",
    "                    trial_speed = a if trial_start_pos == 'LEFT' else -a\n",
    "                elif case == 2:\n",
    "                    trial_start_pos = 'LEFT' if initial_pos < 30 else 'RIGHT'\n",
    "                    trial_speed = a if trial_start_pos == 'RIGHT' else -a\n",
    "                \n",
    "                path = trials[n][case][a][trial]\n",
    "                for location in path:\n",
    "                    y = height + pk - location[0]\n",
    "                    if trial_start_pos == 'CENTER':\n",
    "                        x = width + pk - location[1] if trial_speed < 0 else location[1]\n",
    "                    elif trial_start_pos == 'LEFT':\n",
    "                        x = width + pk - location[1]\n",
    "                    else:\n",
    "                        x = location[1]\n",
    "\n",
    "                    direction_coords[trial_start_pos]['y'][trial_speed].append(y)\n",
    "                    direction_coords[trial_start_pos]['x'][trial_speed].append(x)\n",
    "\n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "def recursively_save_dict_contents(h5group, dictionary):\n",
    "    \"\"\"\n",
    "    Recursively saves a dictionary's contents to an h5py group.\n",
    "    \n",
    "    Parameters:\n",
    "    - h5group: an h5py Group or File object.\n",
    "    - dictionary: the dictionary to save.\n",
    "    \"\"\"\n",
    "    for key, item in dictionary.items():\n",
    "        key_str = str(key)\n",
    "        if isinstance(item, dict):\n",
    "            subgroup = h5group.create_group(key_str)\n",
    "            recursively_save_dict_contents(subgroup, item)\n",
    "        else:\n",
    "            data = np.array(item)\n",
    "            h5group.create_dataset(key_str, data=data)\n",
    "\n",
    "    \n",
    "# -------------------------------------------------------- #\n",
    "\n",
    "with h5py.File('random_mean_coords.h5', 'w') as h5file:\n",
    "    recursively_save_dict_contents(h5file, direction_coords)\n",
    "\n",
    "print(\"Dictionary saved successfully to random_mean_coords.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {0: [plt.get_cmap('Blues')(i) for i in np.arange(0, 1.1, 0.1)], \n",
    "          1: [plt.get_cmap('Oranges')(i) for i in np.arange(0, 1.1, 0.1)], \n",
    "          2: [plt.get_cmap('Reds')(i) for i in np.arange(0, 1.1, 0.1)]}\n",
    "\n",
    "coords = {case: {'y': {pm: [] for pm in range(len(speeds))}, 'x': {pm: [] for pm in range(len(speeds))}} for case in range(len(cases))}\n",
    "mean_coords = {case: {'mean_x': {pm: [] for pm in range(len(speeds))}, 'unique_y': {pm: [] for pm in range(len(speeds))}} for case in range(len(cases))}\n",
    "    \n",
    "for case in range(len(cases)):\n",
    "    for repeat in range(len(repeats)):          \n",
    "        for a in range(len(speeds)):\n",
    "            x_coords, y_coords = [], []\n",
    "            \n",
    "            for trial in trials[repeat][case][a]:\n",
    "                print(trial)\n",
    "                for location in trial:\n",
    "                    y = height + pk - location[0]\n",
    "                    x = width + pk - location[1] if trial[0][1] < trial[-1][1] else location[1]\n",
    "                    y_coords.append(y)\n",
    "                    x_coords.append(x)\n",
    "    \n",
    "            coords[case]['y'][a] = y_coords\n",
    "            coords[case]['x'][a] = x_coords\n",
    "\n",
    "            x_values = np.array(x_coords)\n",
    "            y_values = np.array(y_coords)\n",
    "            unique_ys = np.unique(y_values)\n",
    "\n",
    "            mean_xs = np.array([x_values[y_values == y].mean() for y in unique_ys])\n",
    "            mean_coords[case]['mean_x'][a] = mean_xs\n",
    "            mean_coords[case]['unique_y'][a] = unique_ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(speeds)):\n",
    "    # plt.plot(coords[0]['x'][a], coords[0]['y'][a], color=colors[0][a], alpha=0.01)\n",
    "    plt.plot(mean_coords[0]['mean_x'][a], mean_coords[0]['unique_y'][a], label=np.round(speeds[a], 1), color=colors[0][a])\n",
    "    \n",
    "plt.title('Case 1')\n",
    "plt.axis(\"off\")        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(speeds)):\n",
    "    plt.plot(coords[1]['x'][a], coords[1]['y'][a], color=colors[1][a], alpha=0.01)\n",
    "    plt.plot(mean_coords[1]['mean_x'][a], mean_coords[1]['unique_y'][a], label=np.round(speeds[a], 1), color=colors[1][a])\n",
    "    \n",
    "plt.title('Case 2')\n",
    "plt.axis(\"off\")        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(speeds)):\n",
    "    plt.plot(coords[2]['x'][a], coords[2]['y'][a], color=colors[2][a], alpha=0.01)\n",
    "    plt.plot(mean_coords[2]['mean_x'][a], mean_coords[2]['unique_y'][a], label=np.round(speeds[a], 1), color=colors[2][a])\n",
    "    \n",
    "    \n",
    "plt.title('Case 3')\n",
    "plt.axis(\"off\")        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Approached vs speed\n",
    "cases = [\"1\", \"2\", \"3\"]\n",
    "speeds = np.linspace(start=0.0, stop=1.0, num=10)\n",
    "repeats = [i for i in range(4)]\n",
    "n_trials = 100\n",
    "pe = 0.998\n",
    "noise = 0.002\n",
    "policy = multimodal_mazes.AgentRuleBased.policies[7]\n",
    "agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy=policy)\n",
    "# policy = multimodal_mazes.AgentRuleBasedMemory.policies[0]\n",
    "# agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "colors = [(\"#346ea8\"), (\"#ff760d\"), (\"#fa020f\")]\n",
    "results = np.zeros((len(speeds), len(repeats)))\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True, sharey=True)\n",
    "fig.tight_layout(rect=[0,0.1, 1, 0.9])\n",
    "fig.suptitle(f\"{multisensory} {policy} Percentage Approached vs Speed\")\n",
    "\n",
    "for case in tqdm(range(len(cases))):\n",
    "    approach_results = np.zeros((2, len(speeds)))\n",
    "    for a, speed in tqdm(enumerate(speeds)):\n",
    "        \n",
    "        for b in repeats:\n",
    "            approached = 0\n",
    "            evaluator = multimodal_mazes.LinearPreyFitnessEvaluator(height=height, width=width, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=cases[case], motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=speeds[a], pe=pe)\n",
    "            _, _, _, _, _, approached = evaluator.evaluate(n_trials=n_trials)\n",
    "            results[a, b] = approached\n",
    "        approach_results[0, a] = np.mean(results[a,:])\n",
    "        approach_results[1, a] = np.std(results[a,:])\n",
    "    \n",
    "    for b in repeats:\n",
    "        axs[case].plot(speeds, results[:,b], color = colors[case], alpha = 0.2)\n",
    "        axs[case].set_title(f\"Case {case+1}\")\n",
    "        axs[case].plot(speeds, approach_results[0, :], color=colors[case])\n",
    "        axs[3].plot(speeds, approach_results[0, :], color=colors[case])\n",
    "        axs[case].errorbar(speeds, approach_results[0, :], yerr=approach_results[1, :], color=colors[case])\n",
    "        axs[3].errorbar(speeds, approach_results[0, :], yerr=approach_results[1, :], color=colors[case])\n",
    "\n",
    "axs[0].set(xlabel='Speed', ylabel='Percentage Approached')\n",
    "axs[0].set_xticks(np.arange(0.0, 1.1, 0.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disappearing percentage capture vs visible time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % Approached vs visible time steps poster scaling\n",
    "\n",
    "speeds = [0, 0.25, 0.5, 0.75]\n",
    "repeats = [i for i in range(4)]\n",
    "cases = [\"1\", \"2\", \"3\"]\n",
    "visible_periods = [3, 2, 1, 0]\n",
    "visible_periods_str = ['1', '5', '10', '20']\n",
    "n_trials = 10\n",
    "# policy = multimodal_mazes.AgentRuleBased.policies[7]\n",
    "# agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy=policy)\n",
    "policy = multimodal_mazes.AgentRuleBasedMemory.policies[0]\n",
    "agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "colors = [(\"#346ea8\"), (\"#ff760d\"), (\"#fa020f\")]\n",
    "results = np.zeros((len(visible_periods), len(repeats)))\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True, sharey=True)\n",
    "fig.tight_layout(rect=[0,0.1, 1, 0.9])\n",
    "\n",
    "# Test agents\n",
    "case_results = np.zeros((len(speeds), len(cases), len(visible_periods)))\n",
    "for d, speed in enumerate(speeds):\n",
    "    for a, case in enumerate(cases):\n",
    "        approach_results = np.zeros((2, len(visible_periods)))\n",
    "\n",
    "        for b, period in enumerate(visible_periods):\n",
    "            actual_period = int(visible_periods_str[period])\n",
    "            \n",
    "            for c in repeats:\n",
    "                evaluator = multimodal_mazes.LinearPreyFitnessEvaluator(height=height, width=width, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=case, motion=motion, visible_steps=actual_period, multisensory=multisensory, pc=pc, pm=speed, pe=pe)\n",
    "                _, _, _, _, _, approached = evaluator.evaluate(n_trials=n_trials)\n",
    "            \n",
    "                results[b, c] = approached\n",
    "                \n",
    "            approach_results[0, b] = np.mean(results[b,:])\n",
    "            approach_results[1, b] = np.std(results[b,:])\n",
    "            \n",
    "        case_results[d, a] = approach_results[0]\n",
    "\n",
    "        for c in repeats:\n",
    "            # axs[d].plot(visible_periods, results[:,c], color=colors[a], alpha=0.2)    \n",
    "            axs[d].set_title(f\"Speed {speed}\")  \n",
    "\n",
    "        axs[d].errorbar(visible_periods, approach_results[0, :], yerr=approach_results[1, :], color=colors[a])\n",
    "\n",
    "averaged_case_results = np.mean(case_results, axis=0)\n",
    "        \n",
    "axs[0].set(xlabel='Time to Disapepar', ylabel='Percentage Approached')\n",
    "axs[0].set_xticks(range(4), visible_periods_str);\n",
    "fig.suptitle(f\"{multisensory} {policy} Percentage Approached vs Time to Disappear\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, case in enumerate(averaged_case_results):\n",
    "    plt.plot(visible_periods, case, color=colors[a])\n",
    "\n",
    "plt.xlim(3, 0)\n",
    "plt.xticks(range(4), visible_periods_str);\n",
    "plt.title('Percentage Approached vs Time to Disappear')\n",
    "plt.xlabel('Time to Disappear')\n",
    "plt.ylabel('Percentage Approached')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two prey capture probabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two prey capture probability vs noise\n",
    "n_trials = 100\n",
    "pm = 0\n",
    "noises = np.linspace(start=0.0, stop=1.0, num=10)\n",
    "policies = multimodal_mazes.AgentRuleBased.policies + multimodal_mazes.AgentRuleBasedMemory.policies + [\"Levy\"]\n",
    "colors = multimodal_mazes.AgentRuleBased.colors + multimodal_mazes.AgentRuleBasedMemory.colors + [list(np.array([24, 156, 196, 255]) / 255)]\n",
    "results = np.zeros((len(noises), len(policies)))\n",
    "\n",
    "for a, noise in enumerate(noises):\n",
    "    for b, policy in enumerate(policies): \n",
    "        if policy in multimodal_mazes.AgentRuleBased.policies:\n",
    "            agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy=policy)\n",
    "        elif policy in multimodal_mazes.AgentRuleBasedMemory.policies:\n",
    "            agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "            agnt.alpha = 0.6\n",
    "        elif policy == \"Levy\":\n",
    "            agnt = multimodal_mazes.AgentRandom(location=None, channels=[0,0], motion=policy)\n",
    "\n",
    "        _, _, _, preys, _ = multimodal_mazes.eval_linear_prey_fitness(n_trials=n_trials, height=height, width=width, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=case, visible_steps=visible_steps, multisensory=multisensory, motion=motion, pc=pc, pm=pm, pe=pe)\n",
    "        \n",
    "        ms_captured = 0\n",
    "\n",
    "        for prey in preys:\n",
    "            if prey[0].state == 0:\n",
    "                ms_captured += 1\n",
    "        ms_captured = (ms_captured / n_trials)\n",
    "        results[a, b] = ms_captured\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for b, policy in enumerate(policies): \n",
    "    plt.plot(noises, results[:,b], color=colors[b], label=policy)\n",
    "plt.ylabel('Probability of Multisensory Prey Caught First')\n",
    "plt.xlabel('Noise')\n",
    "plt.yticks(np.arange(0.0, 1.1, 0.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two prey capture probability\n",
    "n_trials = 100\n",
    "policies = multimodal_mazes.AgentRuleBased.policies + multimodal_mazes.AgentRuleBasedMemory.policies + [\"Levy\"]\n",
    "colors = multimodal_mazes.AgentRuleBased.colors + multimodal_mazes.AgentRuleBasedMemory.colors + [list(np.array([24, 156, 196, 255]) / 255)]\n",
    "results = np.zeros((len(policies)))\n",
    "\n",
    "for b, policy in enumerate(policies): \n",
    "    if policy in multimodal_mazes.AgentRuleBased.policies:\n",
    "        agnt = multimodal_mazes.AgentRuleBased(location=None, channels=[1,1], policy=policy)\n",
    "    elif policy in multimodal_mazes.AgentRuleBasedMemory.policies:\n",
    "        agnt = multimodal_mazes.AgentRuleBasedMemory(location=None, channels=[1,1], policy=policy)\n",
    "        agnt.alpha = 0.6\n",
    "    elif policy == \"Levy\":\n",
    "        agnt = multimodal_mazes.AgentRandom(location=None, channels=[0,0], motion=policy)\n",
    "\n",
    "    _, _, _, preys, _, _ = multimodal_mazes.eval_linear_prey_fitness(n_trials=n_trials, height=height, width=width, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=case, visible_steps=visible_steps, multisensory=multisensory, motion=motion, pc=pc, pm=pm, pe=pe)\n",
    "    \n",
    "    ms_captured = 0\n",
    "\n",
    "    for prey in preys:\n",
    "        if prey[0].state == 0:\n",
    "            ms_captured += 1\n",
    "    ms_captured = (ms_captured / n_trials)\n",
    "    results[b] = ms_captured\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for b, policy in enumerate(policies):\n",
    "    plt.scatter(policy, results[b], color=colors[b])\n",
    "    ml, sl, _ = plt.stem(b, results[b])\n",
    "    ml.set_color(colors[b])\n",
    "    sl.set_color(colors[b])\n",
    "plt.ylabel('Probability of Multisensory Prey Caught First')\n",
    "plt.xlabel('Policy')\n",
    "plt.xticks(range(len(policies)), policies, rotation='vertical');\n",
    "plt.yticks(np.arange(0.0, 1.1, 0.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinetic anti-alignment intercept  agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = ['1', '2', '3']\n",
    "speeds = np.linspace(start=0.1, stop=1.0, num=10)\n",
    "n_trials = 250\n",
    "policy='Kinetic alignment'\n",
    "colors = [(\"#346ea8\"), (\"#ff760d\"), (\"#fa020f\")]\n",
    "agnt = multimodal_mazes.AgentIntercept(location=None, channels=[1,1], policy='Kinetic alignment', direction=0)\n",
    "results = np.zeros((len(speeds)))\n",
    "\n",
    "# Test agents\n",
    "for c, case in enumerate(cases):\n",
    "    for a, speed in enumerate(speeds):\n",
    "        evaluator = multimodal_mazes.LinearPreyFitnessEvaluator(height=height, width=width, agnt=agnt, sensor_noise_scale=noise, n_prey=n_prey, pk=pk, n_steps=n_steps, scenario=scenario, case=cases[c], motion=motion, visible_steps=visible_steps, multisensory=multisensory, pc=pc, pm=speed, pe=pe)\n",
    "        _, _, _, _, captured, _ = evaluator.evaluate(n_trials=n_trials)\n",
    "        results[a] = captured      \n",
    "            \n",
    "    for a, speed in enumerate(speeds):\n",
    "        plt.plot(speeds, results[:], color=colors[c])\n",
    "\n",
    "plt.title(f\"{multisensory} {policy} Percentage Captured vs Case\")  \n",
    "plt.xlabel(\"Speed\")\n",
    "plt.ylabel(\"Percentage Captured\")\n",
    "plt.xticks(np.arange(0.0, 1.1, 0.2));\n",
    "#plt.yticks(np.arange(0, 101, 10));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal_mazes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
