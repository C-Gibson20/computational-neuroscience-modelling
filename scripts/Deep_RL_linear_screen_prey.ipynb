{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multimodal_mazes\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters, Hyperparameters and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def environment_hyperparameters():\n",
    "    width = 21\n",
    "    height = 20\n",
    "    pk = 40\n",
    "    pk_hw = 20\n",
    "    capture_radius = 1\n",
    "    return width, height, pk, pk_hw, capture_radius\n",
    "\n",
    "def agent_hyperparameters(width, height, pk_hw):\n",
    "    input_dim = 8\n",
    "    hidden_dim = 10\n",
    "    action_dim = 2\n",
    "    actor_lr = 1.0506603198418105e-05\n",
    "    critic_lr = 0.0005747127451203138\n",
    "    gamma = 0.9197484689502473\n",
    "    tau = 0.0009655446721377356\n",
    "    channels = np.array([1, 1])\n",
    "    location = np.array([pk_hw + height//2, pk_hw + width//2])\n",
    "    # location = np.array([pk_hw, pk_hw + width//2])\n",
    "    return input_dim, hidden_dim, action_dim, actor_lr, critic_lr, gamma, tau, channels, location\n",
    "\n",
    "def static_hyperparamters():\n",
    "    noise = 0.49798430512987657\n",
    "    n_prey = 1\n",
    "    n_steps = 50\n",
    "    scenario =  \"Static\"\n",
    "    motion = None\n",
    "    case = None\n",
    "    multisensory = \"Unisensory\"\n",
    "    speed = 0\n",
    "    pe = 1\n",
    "    pc = 0.0\n",
    "    return noise, n_prey, n_steps, scenario, motion, case, multisensory, speed, pe, pc\n",
    "\n",
    "def constant_hyperparameters():\n",
    "    noise = 0\n",
    "    n_prey = 1\n",
    "    n_steps = 50\n",
    "    scenario =  \"Constant\"\n",
    "    motion = \"Linear\"\n",
    "    case = None\n",
    "    multisensory = \"Unisensory\" \n",
    "    speed = 1\n",
    "    pe = 1\n",
    "    pc = 0.0\n",
    "    return noise, n_prey, n_steps, scenario, motion, case, multisensory, speed, pe, pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Training Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, pk, pk_hw, capture_radius = environment_hyperparameters()\n",
    "input_dim, hidden_dim, action_dim, actor_lr, critic_lr, gamma, tau, channels, location = agent_hyperparameters(width, height, pk_hw)\n",
    "sensor_noise, n_prey, n_steps, scenario, motion, case, multisensory, speed, pe, pc = static_hyperparamters()\n",
    "\n",
    "agent = multimodal_mazes.DDPGAgent(input_dim, hidden_dim, action_dim, actor_lr, critic_lr, gamma, tau, channels, capture_radius, location)\n",
    "training_evaluator = multimodal_mazes.LinearPreyEvaluatorContinuous(width, height, pk_hw, agent, sensor_noise, n_prey, capture_radius, n_steps, n_steps, scenario, motion, case, multisensory, speed, pe, pc)\n",
    "training_evaluator.train_RL(training_trials=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_evaluator.training_plots(plot_training_lengths=True, plot_first_5_last_5=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, pk, pk_hw, capture_radius = environment_hyperparameters()\n",
    "input_dim, hidden_dim, action_dim, actor_lr, critic_lr, gamma, tau, channels, location = agent_hyperparameters(width, height, pk_hw)\n",
    "sensor_noise, n_prey, n_steps, scenario, motion, case, multisensory, speed, pe, pc = static_hyperparamters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna import TrialPruned\n",
    "\n",
    "def ddpg_objective(trial):\n",
    "    # Define the hyperparameters to search\n",
    "    actor_lr = trial.suggest_float('actor_lr', 1e-5, 1e-2, log=True)  # Log scale for learning rates\n",
    "    critic_lr = trial.suggest_float('critic_lr', 1e-5, 1e-2, log=True)\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 8, 256)  # Hidden dimensions for networks\n",
    "    gamma = trial.suggest_float('gamma', 0.8, 0.999)  # Discount factor\n",
    "    tau = trial.suggest_float('tau', 1e-5, 1e-2)  # For soft update of target networks\n",
    "    sensor_noise = trial.suggest_float('noise_scale', 0, 0.5)  # Exploration noise scale\n",
    "\n",
    "    # Create the agent with the hyperparameters from Optuna\n",
    "    agent = multimodal_mazes.DDPGAgent(\n",
    "            input_dim, \n",
    "            hidden_dim, \n",
    "            action_dim, \n",
    "            actor_lr, \n",
    "            critic_lr, \n",
    "            gamma, \n",
    "            tau, \n",
    "            channels, \n",
    "            capture_radius, \n",
    "            location\n",
    "        )\n",
    "\n",
    "    total_reward = 0\n",
    "    \n",
    "    for episode in tqdm(range(1000)):\n",
    "        training_trial_instance = multimodal_mazes.PredatorTrialContinuous(width, height, pk_hw, agent, sensor_noise, n_prey, capture_radius, n_steps, n_steps, scenario, motion, case, multisensory, speed, pe, pc)\n",
    "        training_trial_data = training_trial_instance.run_training_trial()\n",
    "            \n",
    "        total_reward += sum(training_trial_data['rewards'])\n",
    "\n",
    "        trial.report(total_reward, episode)\n",
    "\n",
    "        if episode % 50 == 0:\n",
    "            if trial.should_prune():\n",
    "                raise TrialPruned()\n",
    "\n",
    "    avg_reward = total_reward / 1000\n",
    "\n",
    "    return avg_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a study object to optimize\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner, study_name='DDPG Agent Parameter Tuning')  # We want to maximize the average reward\n",
    "study.optimize(ddpg_objective, n_trials=100)  # Run 100 trials (adjust based on time)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I 2024-09-27 15:37:50,736] A new study created in memory with name: DDPG Agent Parameter Tuning\n",
    "100%|██████████| 1000/1000 [04:04<00:00,  4.09it/s]\n",
    "[I 2024-09-27 15:41:56,086] Trial 0 finished with value: -417.0585519371758 and parameters: {'actor_lr': 0.0087723640956809, 'critic_lr': 1.5837867985802622e-05, 'hidden_dim': 239, 'gamma': 0.9559845620931456, 'tau': 0.007190300323120642, 'noise_scale': 0.3487406545346927}. Best is trial 0 with value: -417.0585519371758.\n",
    "100%|██████████| 1000/1000 [03:31<00:00,  4.74it/s]\n",
    "[I 2024-09-27 15:45:27,116] Trial 1 finished with value: -324.33721673456057 and parameters: {'actor_lr': 0.0009764142920234925, 'critic_lr': 0.00014198380155647632, 'hidden_dim': 241, 'gamma': 0.8040801667714881, 'tau': 0.008899282791554606, 'noise_scale': 0.3973617204717981}. Best is trial 1 with value: -324.33721673456057.\n",
    "100%|██████████| 1000/1000 [02:51<00:00,  5.83it/s]\n",
    "[I 2024-09-27 15:48:18,727] Trial 2 finished with value: -746.7387637383708 and parameters: {'actor_lr': 0.0009346194570029213, 'critic_lr': 0.003953651559753783, 'hidden_dim': 145, 'gamma': 0.9883549896706009, 'tau': 0.000773567996835442, 'noise_scale': 0.026528784020361795}. Best is trial 1 with value: -324.33721673456057.\n",
    "100%|██████████| 1000/1000 [03:59<00:00,  4.18it/s]\n",
    "[I 2024-09-27 15:52:18,207] Trial 3 finished with value: -800.1864961399702 and parameters: {'actor_lr': 1.5740784198163642e-05, 'critic_lr': 0.0038524675662617637, 'hidden_dim': 229, 'gamma': 0.9867768434083477, 'tau': 0.004199554331677343, 'noise_scale': 0.0373331078043076}. Best is trial 1 with value: -324.33721673456057.\n",
    "100%|██████████| 1000/1000 [02:49<00:00,  5.88it/s]\n",
    "[I 2024-09-27 15:55:08,203] Trial 4 finished with value: -781.0711772616644 and parameters: {'actor_lr': 0.0006028524919719193, 'critic_lr': 5.889631327484927e-05, 'hidden_dim': 138, 'gamma': 0.9916123023924568, 'tau': 0.007577590823517911, 'noise_scale': 0.10736156221503468}. Best is trial 1 with value: -324.33721673456057.\n",
    "100%|██████████| 1000/1000 [03:51<00:00,  4.32it/s]\n",
    "[I 2024-09-27 15:58:59,893] Trial 5 finished with value: -811.0558677284141 and parameters: {'actor_lr': 0.00010014764165911945, 'critic_lr': 1.1270249036277267e-05, 'hidden_dim': 215, 'gamma': 0.8634895188699411, 'tau': 0.00951430115512719, 'noise_scale': 0.03546387520753236}. Best is trial 1 with value: -324.33721673456057.\n",
    "100%|██████████| 1000/1000 [02:23<00:00,  6.97it/s]\n",
    "[I 2024-09-27 16:01:23,338] Trial 6 finished with value: -729.3592905029918 and parameters: {'actor_lr': 0.0006840448034259966, 'critic_lr': 0.0008076908006126648, 'hidden_dim': 101, 'gamma': 0.8266172062484001, 'tau': 0.005021742042401841, 'noise_scale': 0.10088122037753611}. Best is trial 1 with value: -324.33721673456057.\n",
    "100%|██████████| 1000/1000 [02:08<00:00,  7.76it/s]\n",
    "[I 2024-09-27 16:03:32,164] Trial 7 finished with value: -266.5839134865015 and parameters: {'actor_lr': 3.156555341888829e-05, 'critic_lr': 0.00013767780322158463, 'hidden_dim': 102, 'gamma': 0.979758738158909, 'tau': 0.009308090322271517, 'noise_scale': 0.4484443819902037}. Best is trial 7 with value: -266.5839134865015.\n",
    "100%|██████████| 1000/1000 [02:19<00:00,  7.15it/s]\n",
    "[I 2024-09-27 16:05:52,112] Trial 8 finished with value: -987.0452388298746 and parameters: {'actor_lr': 0.001264541297527209, 'critic_lr': 2.4359886091447854e-05, 'hidden_dim': 48, 'gamma': 0.8042595921657423, 'tau': 0.0006611580890929267, 'noise_scale': 0.013883448945294308}. Best is trial 7 with value: -266.5839134865015.\n",
    "100%|██████████| 1000/1000 [02:28<00:00,  6.73it/s]\n",
    "[I 2024-09-27 16:08:20,671] Trial 9 finished with value: -783.5608680887241 and parameters: {'actor_lr': 0.0005420955290819098, 'critic_lr': 0.00038974932084839196, 'hidden_dim': 70, 'gamma': 0.9540729396144148, 'tau': 0.006404864928814715, 'noise_scale': 0.0004948111594013094}. Best is trial 7 with value: -266.5839134865015.\n",
    "100%|██████████| 1000/1000 [01:30<00:00, 11.06it/s]\n",
    "[I 2024-09-27 16:09:51,076] Trial 10 finished with value: -244.47979636717886 and parameters: {'actor_lr': 1.2731638101785453e-05, 'critic_lr': 0.000817515236292217, 'hidden_dim': 8, 'gamma': 0.9115849218071568, 'tau': 0.003078162165583782, 'noise_scale': 0.4939903351966581}. Best is trial 10 with value: -244.47979636717886.\n",
    "100%|██████████| 1000/1000 [01:30<00:00, 11.03it/s]\n",
    "[I 2024-09-27 16:11:21,776] Trial 11 finished with value: -226.3789257077783 and parameters: {'actor_lr': 1.3193409368890702e-05, 'critic_lr': 0.001035505525557857, 'hidden_dim': 11, 'gamma': 0.9061981926573026, 'tau': 0.0031788495251878677, 'noise_scale': 0.49671835741773906}. Best is trial 11 with value: -226.3789257077783.\n",
    "...\n",
    "100%|██████████| 1000/1000 [01:19<00:00, 12.58it/s]\n",
    "[I 2024-09-27 18:44:00,174] Trial 98 finished with value: -192.45302088383679 and parameters: {'actor_lr': 1.543848219611113e-05, 'critic_lr': 0.0004363089313868234, 'hidden_dim': 19, 'gamma': 0.9557418507490619, 'tau': 0.0032328123276313234, 'noise_scale': 0.48754761786617307}. Best is trial 46 with value: -134.2939284916707.\n",
    "100%|██████████| 1000/1000 [01:22<00:00, 12.13it/s]\n",
    "[I 2024-09-27 18:45:22,620] Trial 99 finished with value: -201.80471189814202 and parameters: {'actor_lr': 1.1416834016311754e-05, 'critic_lr': 0.0003279227369016091, 'hidden_dim': 40, 'gamma': 0.8748100278595965, 'tau': 0.0023443285915074395, 'noise_scale': 0.45887538929301386}. Best is trial 46 with value: -134.2939284916707.\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n",
    "Best parameters: {'actor_lr': 1.0506603198418105e-05, 'critic_lr': 0.0005747127451203138, 'hidden_dim': 10, 'gamma': 0.9197484689502473, 'tau': 0.0009655446721377356, 'noise_scale': 0.49798430512987657}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize optimization history\n",
    "# optuna.visualization.plot_optimization_history(study)\n",
    "\n",
    "# # Visualize the hyperparameter importance\n",
    "# optuna.visualization.plot_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal_mazes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
